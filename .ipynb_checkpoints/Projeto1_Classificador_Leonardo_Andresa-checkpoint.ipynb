{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nome: Andresa Bicudo\n",
    "\n",
    "#### Nome: Leonardo Malta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO'S:\n",
    "\n",
    "- Separar emojis (de palavras e de emojis)\n",
    "- TABELA RELEVANTE ABSOLUTA + 1 / PALAVRAS RELEVANTES + PALAVRAS TOTAIS\n",
    "- tabela relevante é de todas as palavras, precisamos delas individualmente\n",
    "\n",
    "### Comentários:\n",
    "- soma das palavras dos tweets relevantes = palavras_relevantes\n",
    "- soma das palavras dos tweets irrelevantes = palavras_irrelevantes\n",
    "- $P(Relevante) =$ palavras_relevantes/palavras_totais\n",
    "- $P(Irrelevante) =$ palavras_irrelevantes/palavras_totais\n",
    "- $P(Relevante) + P(Irrelevante) = 1$\n",
    "- palavras_totais = palavras_relevantes + palavras_irrelevantes\n",
    "- $P(tweet|Relevante) = $ DADO\n",
    "- $P(tweet|Irrelevante) = $ DADO\n",
    "- $P(Relevante|tweet) = $ CLASSIFICADOR\n",
    "- $P(Irrelevante|tweet) = $ CLASSIFICADOR\n",
    "- $P(Relevante|tweet) = P(tweet|Relevante)*P(Relevante)/P(tweet)$\n",
    "- $P(Irrelevante|tweet) = P(tweet|Irrelevante)*P(Irrelevante)/P(tweet)$\n",
    "- $P(tweet)$ é a probabilidade da frase ocorrer no espaço amostral total (palavras totais) - será desconsiderada porque ambas as probabilidades medidas pelo classificador, que determinarão se o tweet é relevante ou não, serão divididas por ela. Logo, o resultado qualitativo não se alterará, embora o resukltado quantitativo (percentual se alterará)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importanto bibliotecas\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\user\\Documents\\Insper\\2° semestre\\CDados\\Projetos\\Projeto1_Cdados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('Corona.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Mensagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @joaopauloz_: saber que algumas pessoas com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @thewayjane: se a campeã não sair daqui o c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>na espanha tá feio o corona, tenho medo de que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @george_fredson: dos mesmos criadores de \"a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>as primeiras que vão pega corona vírus aqui na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Relevância                                           Mensagem\n",
       "0           1  rt @joaopauloz_: saber que algumas pessoas com...\n",
       "1           0  rt @thewayjane: se a campeã não sair daqui o c...\n",
       "2           1  na espanha tá feio o corona, tenho medo de que...\n",
       "3           0  rt @george_fredson: dos mesmos criadores de \"a...\n",
       "4           0  as primeiras que vão pega corona vírus aqui na..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faça aqui uma descrição do seu tema e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Em meio a essa grande pandemia do COVID-19 (Corona Vírus), é função Ministério da Saúde auxiliar a população com informações de prevenção e de cuidados cajo haja suspeita de contaminação, logo, tweets informativos são relevantes, uma vez que se pode evitar compartilhamento de \"fake-news\" e manter as recomendações verdadeiras. Ademais, também é essencial que o governo saiba da ocorrência de eventuais eventos que promovem aglomerações e de pessoas que banalizam a situação, a fim de tomar as medidas necessárias para conter o avanço dessa doença. Por fim, como o assunto está sendo extremamente comentado, muitos memes estão sendo feitos, logo, é preciso filtrá-los, recebendo a classificação de não relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Mensagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevante</td>\n",
       "      <td>rt @joaopauloz_: saber que algumas pessoas com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>rt @thewayjane: se a campeã não sair daqui o c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevante</td>\n",
       "      <td>na espanha tá feio o corona, tenho medo de que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>rt @george_fredson: dos mesmos criadores de \"a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>as primeiras que vão pega corona vírus aqui na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Relevância                                           Mensagem\n",
       "0    Relevante  rt @joaopauloz_: saber que algumas pessoas com...\n",
       "1  Irrelevante  rt @thewayjane: se a campeã não sair daqui o c...\n",
       "2    Relevante  na espanha tá feio o corona, tenho medo de que...\n",
       "3  Irrelevante  rt @george_fredson: dos mesmos criadores de \"a...\n",
       "4  Irrelevante  as primeiras que vão pega corona vírus aqui na..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando dados em variaveis qualitativas\n",
    "dados.loc[:,'Mensagem'] = dados['Mensagem'].astype('category')\n",
    "dados.loc[:,'Relevância'] = dados['Relevância'].astype('category')\n",
    "dados.Relevância.cat.categories = ['Irrelevante', 'Relevante']\n",
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @thewayjane: se a campeã não sair daqui o corona já pode cancelar o bbb #bbb20 https://t.co/z4vvf9qn66'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando dados em duas tabelas: Relevantes e Irrelevantes \n",
    "tweets_relevantes = dados.loc[dados['Relevância'] == 'Relevante', :]\n",
    "tweets_irrelevantes = dados.loc[dados['Relevância'] == 'Irrelevante', :]\n",
    "\n",
    "# Teste de seperação de mensagem\n",
    "tweets_irrelevantes.Mensagem[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando listas com os índices dos Tweets relevante e irrelevantes\n",
    "lista_indices_relevantes = []\n",
    "lista_indices_irrelevantes = []\n",
    "\n",
    "for i in range(len(dados.Mensagem)):\n",
    "    if dados.Relevância[i] == 'Relevante':\n",
    "        lista_indices_relevantes.append(dados.index[i])\n",
    "    elif dados.Relevância[i] == 'Irrelevante':\n",
    "        lista_indices_irrelevantes.append(dados.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['se', 'campeã', 'não', 'sair', 'daqui', 'corona', 'já', 'pode', 'cancelar', 'bbb', 'bbb20']\n"
     ]
    }
   ],
   "source": [
    "# Função de limpeza que troca alguns sinais, menções e links por espaços, e coloca em uma lista.\n",
    "# Link de consulta para fazer essa função: \n",
    "# https://stackoverflow.com/questions/54733828/remove-twitter-mentions-from-pandas-column\n",
    "\n",
    "def cleanup(tweet):\n",
    "    tweet_sem_mencoes = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet) # Retirando menções\n",
    "    tweet_sem_links = re.sub(r'http\\S+', '', tweet_sem_mencoes) # Retirando links\n",
    "    punctuation = '[_ ! - . : ? ; @ , # / \" * ( )]' # Sinais que serão substituidos por espaços\n",
    "    pattern = re.compile(punctuation)\n",
    "    tweet_sem_pontuacao = re.sub(pattern, ' ', tweet_sem_links) # Retirando sinais\n",
    "    lista_tweet_semifinal = tweet_sem_pontuacao.split()\n",
    "    # Removendo itens desnecessários para a classificação (retweets - 'rt', e artigos - 'a','o','as','os')\\\n",
    "    itens_desnecessarios = ['rt','a','o','as','os']  \n",
    "    for item in itens_desnecessarios:\n",
    "        for palavra in lista_tweet_semifinal:\n",
    "            if palavra == item:\n",
    "                lista_tweet_semifinal.remove(palavra)\n",
    "            #if palavra == #emoji:\n",
    "                \n",
    "    lista_tweet_final = lista_tweet_semifinal\n",
    "    return lista_tweet_final\n",
    "\n",
    "# Teste do uso da função de limpeza\n",
    "my_str = cleanup(tweets_irrelevantes.Mensagem[1])\n",
    "print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8305\n"
     ]
    }
   ],
   "source": [
    "# Colocando todas a palavras relevantes em uma lista, usando a lista de índices criadas anteriormente:\n",
    "todas_palavras_relevantes = []\n",
    "todas_palavras_irrelevantes = []\n",
    "\n",
    "for i in range(len(lista_indices_relevantes)):\n",
    "    todas_palavras_relevantes.append(cleanup(tweets_relevantes.Mensagem[lista_indices_relevantes[i]]))\n",
    "\n",
    "for p in range(len(lista_indices_irrelevantes)):\n",
    "    todas_palavras_irrelevantes.append(cleanup(tweets_irrelevantes.Mensagem[lista_indices_irrelevantes[p]]))\n",
    "\n",
    "# Trasnformando uma lista de listas em uma única lista:\n",
    "palavras_relevantes = []\n",
    "palavras_irrelevantes = []\n",
    "\n",
    "def Listas2lista(listadelistas):\n",
    "    nova_lista = []\n",
    "    for sublista in listadelistas:\n",
    "        for item in sublista:\n",
    "            nova_lista.append(item)\n",
    "    return nova_lista\n",
    "\n",
    "palavras_relevantes = Listas2lista(todas_palavras_relevantes)\n",
    "palavras_irrelevantes = Listas2lista(todas_palavras_irrelevantes)\n",
    "\n",
    "palvras_relevantes_data = pd.Series(palavras_relevantes)\n",
    "palvras_irrelevantes_data = pd.Series(palavras_irrelevantes)\n",
    "\n",
    "palavras_totais = palavras_relevantes + palavras_irrelevantes\n",
    "\n",
    "print(len(palavras_totais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de qualque palavra ser relevante é de 57.47140276941602%\n",
      "A probabilidade de qualque palavra ser irrelevante é de 42.52859723058398%\n"
     ]
    }
   ],
   "source": [
    "#Probabilidade de ser Relevante ou Irrelevante dentro de todas as palavras da base de treinamento\n",
    "P_relevante = len(palavras_relevantes)/(len(palavras_totais))\n",
    "P_irrelevante = len(palavras_irrelevantes)/(len(palavras_totais))\n",
    "\n",
    "print('A probabilidade de qualque palavra ser relevante é de {0}%'.format((P_relevante*100)))\n",
    "print('A probabilidade de qualque palavra ser irrelevante é de {0}%'.format(P_irrelevante*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corona    252\n",
       "de        102\n",
       "vírus      87\n",
       "que        78\n",
       "eu         71\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabelas de frequências absolutas:\n",
    "tabela_relevantes_abs = palvras_relevantes_data.value_counts()\n",
    "tabela_irrelevantes_abs = palvras_irrelevantes_data.value_counts()\n",
    "tabela_irrelevantes_abs.head()\n",
    "\n",
    "# (tabela_relevante_abs+1)/(len(palavras_relevantes)+len(palavras_totais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corona    0.048188\n",
       "de        0.036874\n",
       "que       0.024513\n",
       "e         0.022627\n",
       "do        0.021580\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabelas de frequências relativas:\n",
    "tabela_relevantes_rel = palvras_relevantes_data.value_counts(True)\n",
    "tabela_irrelevantes_rel = palvras_irrelevantes_data.value_counts(True)\n",
    "tabela_relevantes_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função calcula a Probabilidade de, dado o tweet, este ser relevante ou irrelevante:\n",
    "\n",
    "def calcula_probabilidades(tweet, P_relevante, P_irrelevante):\n",
    "    tweet = cleanup(tweet)\n",
    "    \n",
    "    P_tweet_dado_relevante = tabela_relevantes_abs[tweet].prod()\n",
    "    P_tweet_dado_irrelevante = tabela_irrelevantes_abs[tweet].prod()\n",
    "    \n",
    "    # Uso do Laplace smoothing\n",
    "    P_relevante_dado_tweet = (P_tweet_dado_relevante + 1)/len(palavras_totais) * P_relevante\n",
    "    P_irrelevante_dado_tweet = (P_tweet_dado_irrelevante + 1)/len(palavras_totais) * P_irrelevante\n",
    "    \n",
    "    probabilidades = [P_irrelevante_dado_tweet,P_relevante_dado_tweet]\n",
    "    return probabilidades\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante\n"
     ]
    }
   ],
   "source": [
    "# Teste do Classificador com Tweet aleatório\n",
    "def Classificador(probabilidades):\n",
    "    P_irrelevante_dado_tweet = probabilidades[0]\n",
    "    P_relevante_dado_tweet = probabilidades[1]\n",
    "\n",
    "    if (P_irrelevante_dado_tweet < P_relevante_dado_tweet):\n",
    "        return 'Relevante'\n",
    "    elif (P_irrelevante_dado_tweet > P_relevante_dado_tweet):\n",
    "        return 'Irrelevante'\n",
    "    \n",
    "tweet_teste = \"Para se previnir contra o Corona, lave as mãos com sabão\"\n",
    "\n",
    "teste = Classificador(calcula_probabilidades(tweet_teste, P_relevante, P_irrelevante))\n",
    "\n",
    "print(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-20bc7c565fac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMensagem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMensagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Classificação Treinamento'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassificador\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalcula_probabilidades\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMensagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_relevante\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_irrelevante\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4358\u001b[0m             \u001b[1;31m# try that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4360\u001b[1;33m                 \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 500"
     ]
    }
   ],
   "source": [
    "# Teste do Classificador com dados do Treinamento\n",
    "for i in range(len(dados.Mensagem)):\n",
    "    dados.loc[(dados.Mensagem[i]),'Classificação Treinamento'] = Classificador(calcula_probabilidades(dados.Mensagem[i], P_relevante, P_irrelevante))\n",
    "\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testes para limpeza\n",
    "tweet = tweets_irrelevantes.Mensagem[1]\n",
    "tweet_sem_mencoes = re.sub(\"@[A-Za-z0-9]+\",\"\", tweet) # Retirando menções\n",
    "tweet_sem_links = re.sub(r'http\\S+', '', tweet_sem_mencoes) # Retirando links\n",
    "punctuation = '[_ ! - . : ? ; @ ,]' # Sinais que serão substituidos por espaços\n",
    "pattern = re.compile(punctuation)\n",
    "tweet_sem_pontuacao = re.sub(pattern, ' ', tweet_sem_links) # Retirando sinais\n",
    "lista_tweet_semifinal = tweet_sem_pontuacao.split()\n",
    "    # Removendo itens desnecessários para a classificação (retweets - 'rt', e artigos - 'a','o','as','os')\\\n",
    "lista_tweet_semifinal.remove('rt')\n",
    "lista_tweet_semifinal.remove('o')\n",
    "lista_tweet_semifinal.remove('a')\n",
    "lista_tweet_final = lista_tweet_sem_rt\n",
    "print(lista_tweet_semifinal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
